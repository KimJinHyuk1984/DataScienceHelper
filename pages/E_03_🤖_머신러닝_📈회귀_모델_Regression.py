# pages/3_ğŸ“ˆ_íšŒê·€_ëª¨ë¸_Regression.py
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer # ë°ì´í„°ì…‹ì— ë”°ë¼ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ìš©
from utils.utils_ml import get_dataset, display_regression_metrics # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©

st.header("3. íšŒê·€ ëª¨ë¸ (Regression Models)")
st.markdown("""
íšŒê·€ëŠ” í•˜ë‚˜ ì´ìƒì˜ ë…ë¦½ ë³€ìˆ˜(íŠ¹ì„±)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ì†ì ì¸ ì¢…ì† ë³€ìˆ˜(íƒ€ê²Ÿ)ì˜ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ì§€ë„ í•™ìŠµ ê¸°ë²•ì…ë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, ì£¼íƒì˜ íŠ¹ì§•(í¬ê¸°, ë°© ê°œìˆ˜, ìœ„ì¹˜ ë“±)ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼íƒ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ê±°ë‚˜, ê´‘ê³ ë¹„ ì§€ì¶œì— ë”°ë¥¸ ë§¤ì¶œì•¡ì„ ì˜ˆì¸¡í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

# --- ì˜ˆì œ ë°ì´í„°ì…‹ ë¡œë“œ (ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ë°ì´í„°) ---
st.subheader("ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ íšŒê·€ ì˜ˆì œ")
try:
    df_housing, _, feature_names_housing = get_dataset("california_housing")
except Exception as e:
    st.error(f"ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.info("Scikit-learn ë°ì´í„°ì…‹ ì„œë²„ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    df_housing = None # ì˜¤ë¥˜ ë°œìƒ ì‹œ df_housingì„ Noneìœ¼ë¡œ ì„¤ì •

if df_housing is not None:
    if st.checkbox("ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5í–‰)", key="show_housing_df_page_3"):
        st.dataframe(df_housing.head())
        st.write(f"ë°ì´í„° í˜•íƒœ: {df_housing.shape}")
        st.write("íŠ¹ì„± (Features):", feature_names_housing)
        st.write("íƒ€ê²Ÿ (Target): ì£¼íƒ ê°€ê²© ì¤‘ì•™ê°’ (MedHouseVal)")
        st.write("ê²°ì¸¡ì¹˜ í™•ì¸:")
        st.dataframe(df_housing.isnull().sum().rename("ê²°ì¸¡ì¹˜ ìˆ˜"))

    st.markdown("---")

    # --- 3.1 ë°ì´í„° ì „ì²˜ë¦¬ (íšŒê·€ìš©) ---
    st.subheader("3.1 ë°ì´í„° ì „ì²˜ë¦¬ (íšŒê·€ìš©)")
    st.markdown("""
    íšŒê·€ ëª¨ë¸, íŠ¹íˆ ì„ í˜• ëª¨ë¸ì˜ ê²½ìš° íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ì´ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ íŠ¹ì„±(X)ê³¼ íƒ€ê²Ÿ(y)ì„ ë¶„ë¦¬í•˜ê³ , í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë‚˜ëˆˆ í›„, íŠ¹ì„±ì„ í‘œì¤€í™”í•©ë‹ˆë‹¤.
    """)

    # íŠ¹ì„±(X)ê³¼ íƒ€ê²Ÿ(y) ë¶„ë¦¬
    X_housing = df_housing.drop('target', axis=1)
    y_housing = df_housing['target']

    # í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(X_housing, y_housing, test_size=0.2, random_state=42)

    # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ (StandardScaler ì‚¬ìš©)
    # ì°¸ê³ : ì‹¤ì œë¡œëŠ” í›ˆë ¨ ë°ì´í„°ì— fit_transformì„, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ëŠ” transformë§Œ ì ìš©í•´ì•¼ ë°ì´í„° ìœ ì¶œ(data leakage)ì„ ë°©ì§€í•©ë‹ˆë‹¤.
    scaler_housing = StandardScaler()
    X_train_scaled_h = scaler_housing.fit_transform(X_train_h) # í›ˆë ¨ ë°ì´í„°ë¡œ fit ë° transform
    X_test_scaled_h = scaler_housing.transform(X_test_h)     # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” transformë§Œ

    if st.checkbox("ì „ì²˜ë¦¬ëœ ë°ì´í„° ì¼ë¶€ í™•ì¸", key="show_preprocessed_housing_data_page_3"):
        st.write("í›ˆë ¨ìš© íŠ¹ì„± ë°ì´í„° (ìŠ¤ì¼€ì¼ë§ í›„, ìƒìœ„ 3í–‰):")
        st.dataframe(pd.DataFrame(X_train_scaled_h, columns=X_housing.columns).head(3).round(3))
        st.write("í…ŒìŠ¤íŠ¸ìš© íŠ¹ì„± ë°ì´í„° (ìŠ¤ì¼€ì¼ë§ í›„, ìƒìœ„ 3í–‰):")
        st.dataframe(pd.DataFrame(X_test_scaled_h, columns=X_housing.columns).head(3).round(3))

    st.markdown("---")

    # --- 3.2 ì„ í˜• íšŒê·€ (Linear Regression) ---
    st.subheader("3.2 ì„ í˜• íšŒê·€ (`LinearRegression`)")
    st.markdown("""
    ì„ í˜• íšŒê·€ëŠ” íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ê°„ì˜ ì„ í˜• ê´€ê³„ë¥¼ ê°€ì •í•˜ê³ , ì´ ê´€ê³„ë¥¼ ê°€ì¥ ì˜ ë‚˜íƒ€ë‚´ëŠ” ì§ì„ (ë˜ëŠ” ì´ˆí‰ë©´)ì„ ì°¾ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
    $y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n$ í˜•íƒœì˜ ë°©ì •ì‹ì„ í•™ìŠµí•©ë‹ˆë‹¤.
    - $\beta_0$: ì ˆí¸ (intercept)
    - $\beta_1, ..., \beta_n$: ê° íŠ¹ì„±ì— ëŒ€í•œ ê³„ìˆ˜ (coefficients)
    Scikit-learnì˜ `LinearRegression`ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """)
    code_linear_regression = """
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
# from utils_ml import display_regression_metrics (í‰ê°€ìš©)

# # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (X_train_scaled_h, X_test_scaled_h, y_train_h, y_test_h ì¤€ë¹„ ê°€ì •)
# # ... (ìœ„ì˜ ì „ì²˜ë¦¬ ì½”ë“œì™€ ë™ì¼) ...

# 1. ì„ í˜• íšŒê·€ ëª¨ë¸ ê°ì²´ ìƒì„±
lr_model = LinearRegression()

# 2. ëª¨ë¸ í•™ìŠµ (ìŠ¤ì¼€ì¼ë§ëœ í›ˆë ¨ ë°ì´í„° ì‚¬ìš©)
lr_model.fit(X_train_scaled_h, y_train_h)

# 3. í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡
y_pred_lr = lr_model.predict(X_test_scaled_h)

# 4. ëª¨ë¸ íŒŒë¼ë¯¸í„° í™•ì¸
# print(f"ì ˆí¸ (Intercept): {lr_model.intercept_:.4f}")
# print("ê³„ìˆ˜ (Coefficients):")
# for feature, coef in zip(X_housing.columns, lr_model.coef_):
#     print(f"  - {feature}: {coef:.4f}")

# 5. ëª¨ë¸ í‰ê°€ (utils_mlì˜ display_regression_metrics ì‚¬ìš©)
# display_regression_metrics(y_test_h, y_pred_lr, title="ì„ í˜• íšŒê·€ ëª¨ë¸ í‰ê°€ ê²°ê³¼")
    """
    st.code(code_linear_regression, language='python')

    if st.checkbox("ì„ í˜• íšŒê·€ ëª¨ë¸ ì‹¤í–‰ ë° í‰ê°€ ë³´ê¸°", key="linear_regression_page_3"):
        st.markdown("#### ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡")
        lr_model_ex = LinearRegression()
        lr_model_ex.fit(X_train_scaled_h, y_train_h)
        y_pred_lr_ex = lr_model_ex.predict(X_test_scaled_h)

        st.write(f"**ì ˆí¸ (Intercept, $\\beta_0$):** `{lr_model_ex.intercept_:.4f}`")
        st.write("**ê³„ìˆ˜ (Coefficients, $\\beta_i$):**")
        coef_df = pd.DataFrame({'Feature': X_housing.columns, 'Coefficient': lr_model_ex.coef_}).round(4)
        st.dataframe(coef_df)
        st.caption("ê³„ìˆ˜ì˜ ì ˆëŒ€ê°’ì´ í´ìˆ˜ë¡ í•´ë‹¹ íŠ¹ì„±ì´ íƒ€ê²Ÿ ë³€ìˆ˜ì— ë” í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤ê³  (ì„ í˜•ì ìœ¼ë¡œ) í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ê¸°ì¤€).")
        
        # í‰ê°€ì§€í‘œ í‘œì‹œ
        display_regression_metrics(y_test_h, y_pred_lr_ex, title="ì„ í˜• íšŒê·€ ëª¨ë¸ í‰ê°€ ê²°ê³¼")

    st.markdown("---")

    # --- 3.3 ê¸°íƒ€ íšŒê·€ ëª¨ë¸ (ê°„ëµ ì†Œê°œ) ---
    st.subheader("3.3 ê¸°íƒ€ ì£¼ìš” íšŒê·€ ëª¨ë¸ (ê°„ëµ ì†Œê°œ)")
    st.markdown("""
    ì„ í˜• íšŒê·€ ì™¸ì—ë„ ë‹¤ì–‘í•œ íšŒê·€ ì•Œê³ ë¦¬ì¦˜ì´ ìˆìœ¼ë©°, ë°ì´í„°ì˜ íŠ¹ì„±ì´ë‚˜ ë¬¸ì œ ìƒí™©ì— ë”°ë¼ ë” ì í•©í•œ ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)

    # --- Ridge íšŒê·€ ---
    st.markdown("#### ë¦¿ì§€ íšŒê·€ (`Ridge`)")
    st.markdown("""
    ì„ í˜• íšŒê·€ì— L2 ê·œì œ(regularization)ë¥¼ ì¶”ê°€í•œ ëª¨ë¸ì…ë‹ˆë‹¤. ê³„ìˆ˜ì˜ í¬ê¸°ë¥¼ ì¤„ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
    `alpha` íŒŒë¼ë¯¸í„°ë¡œ ê·œì œ ê°•ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤ (í´ìˆ˜ë¡ ê·œì œê°€ ê°•í•´ì§).
    """)
    code_ridge = """
from sklearn.linear_model import Ridge

# Ridge ëª¨ë¸ ê°ì²´ ìƒì„± (alpha ê°’ì€ íŠœë‹ í•„ìš”)
ridge_model = Ridge(alpha=1.0) 

# ëª¨ë¸ í•™ìŠµ
# ridge_model.fit(X_train_scaled_h, y_train_h)

# ì˜ˆì¸¡
# y_pred_ridge = ridge_model.predict(X_test_scaled_h)
# display_regression_metrics(y_test_h, y_pred_ridge, title="Ridge íšŒê·€ ëª¨ë¸ í‰ê°€ ê²°ê³¼ (alpha=1.0)")
    """
    st.code(code_ridge, language='python')
    if st.checkbox("Ridge íšŒê·€ ì˜ˆì‹œ ì‹¤í–‰ (alpha=1.0)", key="ridge_page_3"):
        ridge_model_ex = Ridge(alpha=1.0)
        ridge_model_ex.fit(X_train_scaled_h, y_train_h)
        y_pred_ridge_ex = ridge_model_ex.predict(X_test_scaled_h)
        display_regression_metrics(y_test_h, y_pred_ridge_ex, title="Ridge íšŒê·€ (alpha=1.0) í‰ê°€ ê²°ê³¼")


    # --- Lasso íšŒê·€ ---
    st.markdown("#### ë¼ì˜ íšŒê·€ (`Lasso`)")
    st.markdown("""
    ì„ í˜• íšŒê·€ì— L1 ê·œì œë¥¼ ì¶”ê°€í•œ ëª¨ë¸ì…ë‹ˆë‹¤. ì¼ë¶€ íŠ¹ì„±ì˜ ê³„ìˆ˜ë¥¼ ì •í™•íˆ 0ìœ¼ë¡œ ë§Œë“¤ì–´ íŠ¹ì„± ì„ íƒ(feature selection) íš¨ê³¼ë¥¼ ê°€ì§‘ë‹ˆë‹¤.
    `alpha` íŒŒë¼ë¯¸í„°ë¡œ ê·œì œ ê°•ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.
    """)
    code_lasso = """
from sklearn.linear_model import Lasso

# Lasso ëª¨ë¸ ê°ì²´ ìƒì„± (alpha ê°’ì€ íŠœë‹ í•„ìš”)
lasso_model = Lasso(alpha=0.1) # alphaê°€ ë„ˆë¬´ í¬ë©´ ë§ì€ ê³„ìˆ˜ê°€ 0ì´ ë  ìˆ˜ ìˆìŒ

# ëª¨ë¸ í•™ìŠµ
# lasso_model.fit(X_train_scaled_h, y_train_h)

# ì˜ˆì¸¡
# y_pred_lasso = lasso_model.predict(X_test_scaled_h)
# display_regression_metrics(y_test_h, y_pred_lasso, title="Lasso íšŒê·€ ëª¨ë¸ í‰ê°€ ê²°ê³¼ (alpha=0.1)")
# print("Lasso ê³„ìˆ˜ ì¤‘ 0ì´ ì•„ë‹Œ ê²ƒì˜ ê°œìˆ˜:", np.sum(lasso_model.coef_ != 0))
    """
    st.code(code_lasso, language='python')
    if st.checkbox("Lasso íšŒê·€ ì˜ˆì‹œ ì‹¤í–‰ (alpha=0.01)", key="lasso_page_3"): # alpha ì¡°ì •
        lasso_model_ex = Lasso(alpha=0.01) # alphaë¥¼ ì¡°ê¸ˆ ì‘ê²Œ ì„¤ì •í•˜ì—¬ ë„ˆë¬´ ë§ì€ ê³„ìˆ˜ê°€ 0ì´ ë˜ëŠ” ê²ƒì„ ë°©ì§€
        lasso_model_ex.fit(X_train_scaled_h, y_train_h)
        y_pred_lasso_ex = lasso_model_ex.predict(X_test_scaled_h)
        display_regression_metrics(y_test_h, y_pred_lasso_ex, title="Lasso íšŒê·€ (alpha=0.01) í‰ê°€ ê²°ê³¼")
        st.write(f"Lasso ëª¨ë¸ ê³„ìˆ˜ (0ì´ ì•„ë‹Œ ê²ƒ ê°œìˆ˜: {np.sum(lasso_model_ex.coef_ != 0)} / ì´ {len(lasso_model_ex.coef_)} ê°œ):")
        lasso_coef_df = pd.DataFrame({'Feature': X_housing.columns, 'Coefficient': lasso_model_ex.coef_}).round(4)
        st.dataframe(lasso_coef_df[lasso_coef_df['Coefficient'] != 0]) # 0ì´ ì•„ë‹Œ ê³„ìˆ˜ë§Œ í‘œì‹œ


    # --- ê²°ì • íŠ¸ë¦¬ íšŒê·€ ---
    st.markdown("#### ê²°ì • íŠ¸ë¦¬ íšŒê·€ (`DecisionTreeRegressor`)")
    st.markdown("""
    ë°ì´í„°ë¥¼ íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ë¶„í• í•˜ë©° ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë¹„ì„ í˜• ê´€ê³„ë„ í•™ìŠµí•  ìˆ˜ ìˆì§€ë§Œ, ê³¼ì í•©ë˜ê¸° ì‰¬ìš´ ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.
    ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°: `max_depth` (íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´), `min_samples_split` (ë¶„í• ì„ ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜), `min_samples_leaf` (ë¦¬í”„ ë…¸ë“œì˜ ìµœì†Œ ìƒ˜í”Œ ìˆ˜).
    """)
    code_dt_reg = """
from sklearn.tree import DecisionTreeRegressor

# Decision Tree Regressor ëª¨ë¸ ê°ì²´ ìƒì„±
dt_reg_model = DecisionTreeRegressor(max_depth=5, random_state=42)

# ëª¨ë¸ í•™ìŠµ
# dt_reg_model.fit(X_train_scaled_h, y_train_h) # ìŠ¤ì¼€ì¼ë§ì€ íŠ¸ë¦¬ê¸°ë°˜ ëª¨ë¸ì— í•„ìˆ˜ ì•„ë‹˜

# ì˜ˆì¸¡
# y_pred_dt_reg = dt_reg_model.predict(X_test_scaled_h)
# display_regression_metrics(y_test_h, y_pred_dt_reg, title="ê²°ì • íŠ¸ë¦¬ íšŒê·€ ëª¨ë¸ í‰ê°€ ê²°ê³¼ (max_depth=5)")
    """
    st.code(code_dt_reg, language='python')
    if st.checkbox("ê²°ì • íŠ¸ë¦¬ íšŒê·€ ì˜ˆì‹œ ì‹¤í–‰ (max_depth=5)", key="dt_reg_page_3"):
        dt_reg_model_ex = DecisionTreeRegressor(max_depth=5, random_state=42)
        # íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì€ ìŠ¤ì¼€ì¼ë§ì´ í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ, ì¼ê´€ì„±ì„ ìœ„í•´ ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ì‚¬ìš©
        dt_reg_model_ex.fit(X_train_scaled_h, y_train_h)
        y_pred_dt_reg_ex = dt_reg_model_ex.predict(X_test_scaled_h)
        display_regression_metrics(y_test_h, y_pred_dt_reg_ex, title="ê²°ì • íŠ¸ë¦¬ íšŒê·€ (max_depth=5) í‰ê°€ ê²°ê³¼")


    # --- ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ---
    st.markdown("#### ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ (`RandomForestRegressor`)")
    st.markdown("""
    ì—¬ëŸ¬ ê°œì˜ ê²°ì • íŠ¸ë¦¬ë¥¼ ì•™ìƒë¸”(ensemble)í•˜ì—¬ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë†’ì´ê³  ê³¼ì í•©ì„ ì¤„ì¸ ëª¨ë¸ì…ë‹ˆë‹¤.
    ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°: `n_estimators` (íŠ¸ë¦¬ ê°œìˆ˜), `max_depth`, `min_samples_split`, `min_samples_leaf`.
    """)
    code_rf_reg = """
from sklearn.ensemble import RandomForestRegressor

# Random Forest Regressor ëª¨ë¸ ê°ì²´ ìƒì„±
rf_reg_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1) # n_jobs=-1: ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©

# ëª¨ë¸ í•™ìŠµ
# rf_reg_model.fit(X_train_scaled_h, y_train_h)

# ì˜ˆì¸¡
# y_pred_rf_reg = rf_reg_model.predict(X_test_scaled_h)
# display_regression_metrics(y_test_h, y_pred_rf_reg, title="ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸ í‰ê°€ ê²°ê³¼ (n_estimators=100, max_depth=10)")
    """
    st.code(code_rf_reg, language='python')
    if st.checkbox("ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ì˜ˆì‹œ ì‹¤í–‰ (n_estimators=50, max_depth=8)", key="rf_reg_page_3"): # íŒŒë¼ë¯¸í„° ì•½ê°„ ì¤„ì„
        st.caption("ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” í•™ìŠµì— ë‹¤ì†Œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
        rf_reg_model_ex = RandomForestRegressor(n_estimators=50, max_depth=8, random_state=42, n_jobs=-1)
        rf_reg_model_ex.fit(X_train_scaled_h, y_train_h)
        y_pred_rf_reg_ex = rf_reg_model_ex.predict(X_test_scaled_h)
        display_regression_metrics(y_test_h, y_pred_rf_reg_ex, title="ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ (n_estimators=50, max_depth=8) í‰ê°€ ê²°ê³¼")

    st.markdown("---")
    st.markdown("ì´ ì™¸ì—ë„ Support Vector Regressor (SVR), Gradient Boosting Regressor, XGBoost, LightGBM ë“± ë‹¤ì–‘í•œ ê³ ê¸‰ íšŒê·€ ëª¨ë¸ë“¤ì´ ìˆìŠµë‹ˆë‹¤. ê° ëª¨ë¸ì˜ íŠ¹ì„±ì„ ì´í•´í•˜ê³  ë°ì´í„°ì— ì í•©í•œ ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.")

else: # df_housingì´ Noneì¼ ê²½ìš° (ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨)
    st.error("ë°ì´í„°ì…‹ì„ ë¡œë“œí•  ìˆ˜ ì—†ì–´ íšŒê·€ ëª¨ë¸ ì˜ˆì œë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.markdown("ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜, Scikit-learn ë°ì´í„°ì…‹ ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. (`fetch_california_housing`)")