# pages/6_ğŸ“_ì°¨ì›_ì¶•ì†Œ_PCA.py
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from utils.utils_ml import get_dataset # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
import seaborn as sns

st.header("6. ì°¨ì› ì¶•ì†Œ (Dimensionality Reduction) - PCA")
st.markdown("""
ì°¨ì› ì¶•ì†ŒëŠ” ë°ì´í„°ì˜ íŠ¹ì„±(feature) ìˆ˜ë¥¼ ì¤„ì´ë©´ì„œ ì›ë˜ ë°ì´í„°ì˜ ì¤‘ìš”í•œ ì •ë³´ëŠ” ìµœëŒ€í•œ ìœ ì§€í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.
ê³ ì°¨ì› ë°ì´í„°ëŠ” ì‹œê°í™”ê°€ ì–´ë µê³ , 'ì°¨ì›ì˜ ì €ì£¼(curse of dimensionality)'ë¡œ ì¸í•´ ëª¨ë¸ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì°¨ì› ì¶•ì†Œë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë” ì˜ ì´í•´í•˜ê³ , ëª¨ë¸ í•™ìŠµ ì†ë„ë¥¼ ë†’ì´ë©°, ê³¼ì í•©ì„ ì¤„ì´ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì—¬ê¸°ì„œëŠ” ëŒ€í‘œì ì¸ ì°¨ì› ì¶•ì†Œ ê¸°ë²•ì¸ **ì£¼ì„±ë¶„ ë¶„ì„ (Principal Component Analysis, PCA)**ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.
""")

# --- ì˜ˆì œ ë°ì´í„°ì…‹ ë¡œë“œ (ì™€ì¸ ë˜ëŠ” ìœ ë°©ì•” ë°ì´í„° - ë‹¤ìˆ˜ì˜ íŠ¹ì„±ì„ ê°€ì§) ---
st.subheader("PCA ì˜ˆì œìš© ë°ì´í„°ì…‹ (ì™€ì¸ ë˜ëŠ” ìœ ë°©ì•” ë°ì´í„°)")
dataset_options_pca = ["wine", "breast_cancer", "iris"] # Irisë„ ë¹„êµì  ì ì€ íŠ¹ì„±ì´ì§€ë§Œ ê°€ëŠ¥
chosen_dataset_pca = st.selectbox(
    "PCA ì˜ˆì œì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ì„ ì„ íƒí•˜ì„¸ìš”:",
    dataset_options_pca,
    index=0, # ê¸°ë³¸ê°’ 'wine'
    key="pca_dataset_selector"
)

try:
    df_pca_orig, target_names_pca, feature_names_pca = get_dataset(chosen_dataset_pca)
    X_pca_orig = df_pca_orig.drop('target', axis=1)
    y_pca_orig = df_pca_orig['target']
except Exception as e:
    st.error(f"{chosen_dataset_pca} ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    df_pca_orig = None
    X_pca_orig = None
    y_pca_orig = None

if df_pca_orig is not None and X_pca_orig is not None:
    if st.checkbox(f"{chosen_dataset_pca} ì›ë³¸ ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5í–‰)", key=f"show_{chosen_dataset_pca}_df_page_6"):
        st.dataframe(X_pca_orig.head())
        st.write(f"ì›ë³¸ ë°ì´í„° í˜•íƒœ (íŠ¹ì„±): {X_pca_orig.shape}")
        st.write("íŠ¹ì„± (Features):", feature_names_pca)
        st.write("ê²°ì¸¡ì¹˜ í™•ì¸:")
        st.dataframe(X_pca_orig.isnull().sum().rename("ê²°ì¸¡ì¹˜ ìˆ˜"))

    st.markdown("---")

    # --- 6.1 ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (PCA ì „ì²˜ë¦¬) ---
    st.subheader("6.1 ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (PCA ì „ì²˜ë¦¬)")
    st.markdown("""
    PCAëŠ” ë°ì´í„°ì˜ ë¶„ì‚°(variance)ì„ ê¸°ë°˜ìœ¼ë¡œ ì£¼ì„±ë¶„ì„ ì°¾ìœ¼ë¯€ë¡œ, íŠ¹ì„±ë“¤ì˜ ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥´ë©´ ë¶„ì‚°ì´ í° íŠ¹ì„±ì´ ì£¼ì„±ë¶„ì— ê³¼ë„í•œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ë”°ë¼ì„œ PCA ì ìš© ì „ì— ê° íŠ¹ì„±ì„ **í‘œì¤€í™”(Standardization)**í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.
    """)

    scaler_pca = StandardScaler()
    X_pca_scaled = scaler_pca.fit_transform(X_pca_orig)
    
    df_pca_scaled = pd.DataFrame(X_pca_scaled, columns=feature_names_pca)

    if st.checkbox("ìŠ¤ì¼€ì¼ë§ëœ PCA ì…ë ¥ ë°ì´í„° ì¼ë¶€ í™•ì¸", key="show_preprocessed_pca_data_page_6"):
        st.write("íŠ¹ì„± ë°ì´í„° (ìŠ¤ì¼€ì¼ë§ í›„, ìƒìœ„ 5í–‰):")
        st.dataframe(df_pca_scaled.head().round(3))
        st.caption(f"ìŠ¤ì¼€ì¼ë§ í›„ ê° íŠ¹ì„±ì˜ í‰ê· : {df_pca_scaled.mean().mean():.2e}, í‘œì¤€í¸ì°¨: {df_pca_scaled.std().mean():.2f} (ê°ê° 0ê³¼ 1ì— ê°€ê¹Œì›Œì•¼ í•¨)")


    st.markdown("---")

    # --- 6.2 ì£¼ì„±ë¶„ ë¶„ì„ (PCA) ---
    st.subheader("6.2 ì£¼ì„±ë¶„ ë¶„ì„ (`PCA`)")
    st.markdown(f"""
    PCAëŠ” ë°ì´í„°ì˜ ë¶„ì‚°ì´ ê°€ì¥ í° ë°©í–¥ì„ ì²« ë²ˆì§¸ ì£¼ì„±ë¶„(PC1)ìœ¼ë¡œ, ê·¸ ë‹¤ìŒìœ¼ë¡œ ë¶„ì‚°ì´ í° (PC1ê³¼ ì§êµí•˜ëŠ”) ë°©í–¥ì„ ë‘ ë²ˆì§¸ ì£¼ì„±ë¶„(PC2)ìœ¼ë¡œ ì°¾ëŠ” ë°©ì‹ìœ¼ë¡œ ì£¼ì„±ë¶„ë“¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    ì›ë˜ íŠ¹ì„± ê³µê°„ì„ ìƒˆë¡œìš´ (ë” ë‚®ì€ ì°¨ì›ì˜) ì£¼ì„±ë¶„ ê³µê°„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°:
    - `n_components`: ìœ ì§€í•  ì£¼ì„±ë¶„ì˜ ê°œìˆ˜.
        - ì •ìˆ˜: ì£¼ì„±ë¶„ ê°œìˆ˜ë¥¼ ì§ì ‘ ì§€ì •.
        - `0 < n_components < 1` (ì‹¤ìˆ˜): ìœ ì§€í•  ì´ ë¶„ì‚°ì˜ ë¹„ìœ¨ì„ ì§€ì • (ì˜ˆ: `0.95`ëŠ” ë¶„ì‚°ì˜ 95%ë¥¼ ì„¤ëª…í•˜ëŠ” ì£¼ì„±ë¶„ ê°œìˆ˜ ìë™ ì„ íƒ).
        - `None`: ëª¨ë“  ì£¼ì„±ë¶„ì„ ìœ ì§€ (`min(n_samples, n_features)`).
    - `random_state`: (ì†”ë²„ê°€ í™•ë¥ ì ì¼ ê²½ìš°) ê²°ê³¼ ì¬í˜„ì„ ìœ„í•œ ì‹œë“œ.
    """)



    n_features = X_pca_scaled.shape[1]
    pca_n_components = st.slider(
        "PCAì—ì„œ ìœ ì§€í•  ì£¼ì„±ë¶„(n_components) ê°œìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        min_value=1, 
        max_value=n_features, 
        value=min(2, n_features),
        key="pca_n_components_slider_page_6_v2" # í‚¤ ë³€ê²½
    )

    # f-string ëŒ€ì‹  .format()ê³¼ ì´ì¤‘ ì¤‘ê´„í˜¸ ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
    code_pca = """
from sklearn.decomposition import PCA
# from sklearn.preprocessing import StandardScaler (ìŠ¤ì¼€ì¼ë§ì€ ì´ë¯¸ ì™„ë£Œ ê°€ì •)
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt

# # ë°ì´í„° ì¤€ë¹„ (X_pca_scaled ì‚¬ìš© ê°€ì •)

# 1. PCA ëª¨ë¸ ê°ì²´ ìƒì„±
# n_components: ìœ ì§€í•  ì£¼ì„±ë¶„ì˜ ê°œìˆ˜. ì—¬ê¸°ì„œëŠ” {n_comps_val}ë¡œ ì„¤ì •.
pca = PCA(n_components={n_comps_val}, random_state=42)

# 2. PCA ëª¨ë¸ í•™ìŠµ ë° ë°ì´í„° ë³€í™˜
# fit_transform()ì€ ì£¼ì„±ë¶„ì„ ì°¾ê³ (fit), ë°ì´í„°ë¥¼ í•´ë‹¹ ì£¼ì„±ë¶„ ê³µê°„ìœ¼ë¡œ ë³€í™˜(transform)í•©ë‹ˆë‹¤.
X_pca_transformed = pca.fit_transform(X_pca_scaled)

# # ë³€í™˜ëœ ë°ì´í„° í™•ì¸
# print(f"ì›ë³¸ ë°ì´í„° í˜•íƒœ: {{X_pca_scaled.shape}}") # ì´ì¤‘ ì¤‘ê´„í˜¸ë¡œ ì´ìŠ¤ì¼€ì´í”„
# print(f"PCA ë³€í™˜ í›„ ë°ì´í„° í˜•íƒœ: {{X_pca_transformed.shape}}") # ì´ì¤‘ ì¤‘ê´„í˜¸ë¡œ ì´ìŠ¤ì¼€ì´í”„
# df_pca_result = pd.DataFrame(X_pca_transformed, columns=[f'PC{{i+1}}' for i in range(X_pca_transformed.shape[1])]) # ë‚´ë¶€ f-stringì˜ i ë³€ìˆ˜ ë¶€ë¶„ë„ ì´ìŠ¤ì¼€ì´í”„
# print("\\nPCA ë³€í™˜ ë°ì´í„° (ìƒìœ„ 5í–‰):\\n", df_pca_result.head().round(3))

# # ì„¤ëª…ëœ ë¶„ì‚° (Explained Variance)
# # ê° ì£¼ì„±ë¶„ì´ ì›ë³¸ ë°ì´í„°ì˜ ë¶„ì‚°ì„ ì–¼ë§ˆë‚˜ ì„¤ëª…í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
explained_variance_ratio = pca.explained_variance_ratio_
# print("\\nê° ì£¼ì„±ë¶„ì˜ ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨:", np.round(explained_variance_ratio, 4))
# print(f"ì„ íƒëœ {n_comps_val}ê°œ ì£¼ì„±ë¶„ìœ¼ë¡œ ì„¤ëª…ë˜ëŠ” ì´ ë¶„ì‚° ë¹„ìœ¨: {{np.sum(explained_variance_ratio):.4f}}") # ì´ì¤‘ ì¤‘ê´„í˜¸ ë° n_comps_val ì‚¬ìš©

# # (ì„ íƒ ì‚¬í•­) ì£¼ì„±ë¶„ ë¡œë”© (Principal Component Loadings)
# # ê° ì£¼ì„±ë¶„ì´ ì›ë˜ íŠ¹ì„±ë“¤ê³¼ ì–´ë–¤ ê´€ê³„ë¥¼ ê°€ì§€ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤. (pca.components_)
# # feature_names_pca ë³€ìˆ˜ëŠ” ì´ ì½”ë“œ ë¸”ë¡ ë°”ê¹¥ ìŠ¤ì½”í”„ì— ìˆì–´ì•¼ í•¨ (ì‹¤ì œë¡œëŠ” ìˆìŒ)
# loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{{i+1}}' for i in range(pca.n_components_)], index=feature_names_pca) # ë‚´ë¶€ f-stringì˜ i ë³€ìˆ˜ ë¶€ë¶„ ì´ìŠ¤ì¼€ì´í”„
# print("\\nì£¼ì„±ë¶„ ë¡œë”©:\\n", loadings.round(3))
    """.format(n_comps_val=pca_n_components) # .format()ìœ¼ë¡œ ì™¸ë¶€ ë³€ìˆ˜ ì£¼ì…

    st.code(code_pca, language='python')

    if st.button(f"PCA ì‹¤í–‰ (n_components={pca_n_components})", key="run_pca_page_6_v2"): # í‚¤ ë³€ê²½
        # ... (ì´í•˜ ì‹¤í–‰ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€) ...
        st.markdown(f"#### PCA ê²°ê³¼ (n_components={pca_n_components})")
        
        pca_ex = PCA(n_components=pca_n_components, random_state=42)
        X_pca_transformed_ex = pca_ex.fit_transform(X_pca_scaled)

        df_pca_result_ex = pd.DataFrame(
            X_pca_transformed_ex, 
            columns=[f'PC{i+1}' for i in range(pca_n_components)]
        )
        st.write(f"PCA ë³€í™˜ í›„ ë°ì´í„° í˜•íƒœ: `{X_pca_transformed_ex.shape}`")
        st.write("PCA ë³€í™˜ ë°ì´í„° (ìƒìœ„ 5í–‰):")
        st.dataframe(df_pca_result_ex.head().round(3))

        st.markdown("##### ì„¤ëª…ëœ ë¶„ì‚° (Explained Variance)")
        explained_variance_ratio_ex = pca_ex.explained_variance_ratio_
        explained_variance_df = pd.DataFrame({
            'ì£¼ì„±ë¶„ (Principal Component)': [f'PC{i+1}' for i in range(pca_n_components)],
            'ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨ (Explained Variance Ratio)': explained_variance_ratio_ex
        }).set_index('ì£¼ì„±ë¶„ (Principal Component)')
        
        st.dataframe(explained_variance_df.style.format({'ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨ (Explained Variance Ratio)': "{:.4f}"}))
        st.metric(
            label=f"ì„ íƒëœ {pca_n_components}ê°œ ì£¼ì„±ë¶„ìœ¼ë¡œ ì„¤ëª…ë˜ëŠ” ì´ ë¶„ì‚° ë¹„ìœ¨",
            value=f"{np.sum(explained_variance_ratio_ex):.4f}"
        )

        # ... (ì´í•˜ ëˆ„ì  ì„¤ëª… ë¶„ì‚° ê·¸ë˜í”„ ë° 2D ì‹œê°í™” ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€) ...
        if pca_n_components > 1 and pca_n_components <= n_features :
            pca_full = PCA(n_components=None, random_state=42)
            pca_full.fit(X_pca_scaled)
            
            fig_explained_var, ax_explained_var = plt.subplots(figsize=(8,5))
            ax_explained_var.plot(
                np.arange(1, len(pca_full.explained_variance_ratio_) + 1),
                np.cumsum(pca_full.explained_variance_ratio_),
                marker='o', linestyle='--'
            )
            ax_explained_var.set_xlabel("ì£¼ì„±ë¶„ ê°œìˆ˜")
            ax_explained_var.set_ylabel("ëˆ„ì  ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨ (Cumulative Explained Variance)")
            ax_explained_var.set_title("ì£¼ì„±ë¶„ ê°œìˆ˜ì— ë”°ë¥¸ ëˆ„ì  ì„¤ëª… ë¶„ì‚°")
            ax_explained_var.grid(True, linestyle=':', alpha=0.7)
            if pca_n_components <= len(pca_full.explained_variance_ratio_):
                ax_explained_var.axvline(x=pca_n_components, color='red', linestyle=':', label=f'ì„ íƒëœ ê°œìˆ˜: {pca_n_components}')
                ax_explained_var.axhline(y=np.sum(explained_variance_ratio_ex), color='green', linestyle=':', label=f'í˜„ì¬ ì„¤ëª… ë¶„ì‚°: {np.sum(explained_variance_ratio_ex):.2f}')
                ax_explained_var.legend()
            st.pyplot(fig_explained_var)
            plt.clf()

        if pca_n_components >= 2 and y_pca_orig is not None:
            st.markdown("##### PCA ë³€í™˜ ë°ì´í„° 2D ì‹œê°í™” (PC1 vs PC2)")
            df_pca_plot = pd.DataFrame(X_pca_transformed_ex[:, :2], columns=['PC1', 'PC2'])
            df_pca_plot['target'] = y_pca_orig

            fig_pca_scatter, ax_pca_scatter = plt.subplots(figsize=(9,7))
            if target_names_pca is not None:
                unique_targets = sorted(df_pca_plot['target'].unique())
                palette = sns.color_palette("deep", len(unique_targets))
                for i, target_val in enumerate(unique_targets): # ë³€ìˆ˜ ì´ë¦„ target_valë¡œ ë³€ê²½
                    subset = df_pca_plot[df_pca_plot['target'] == target_val] # target_val ì‚¬ìš©
                    ax_pca_scatter.scatter(subset['PC1'], subset['PC2'], label=target_names_pca[target_val], alpha=0.8, s=70, edgecolor='k', color=palette[i % len(palette)])
                ax_pca_scatter.legend(title=f"{chosen_dataset_pca.capitalize()} Classes", title_fontsize='13')
            else:
                ax_pca_scatter.scatter(df_pca_plot['PC1'], df_pca_plot['PC2'], alpha=0.7, s=50, edgecolor='k')

            ax_pca_scatter.set_xlabel("ì£¼ì„±ë¶„ 1 (Principal Component 1)")
            ax_pca_scatter.set_ylabel("ì£¼ì„±ë¶„ 2 (Principal Component 2)")
            ax_pca_scatter.set_title(f"{chosen_dataset_pca.capitalize()} ë°ì´í„°ì˜ PCA 2D ì‹œê°í™”")
            ax_pca_scatter.grid(True, linestyle=':', alpha=0.6)
            st.pyplot(fig_pca_scatter)
            plt.clf()

    


    st.markdown("---")
    st.markdown("""
    PCAëŠ” ë°ì´í„° ì‹œê°í™”, ë…¸ì´ì¦ˆ ì œê±°, íŠ¹ì„± ê³µí•™, ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì…ë ¥ ì°¨ì› ì¶•ì†Œ ë“± ë‹¤ì–‘í•˜ê²Œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ì ì ˆí•œ ì£¼ì„±ë¶„ ê°œìˆ˜ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ì´ëŠ” ë³´í†µ 'ì„¤ëª…ëœ ë¶„ì‚°'ì„ ê³ ë ¤í•˜ì—¬ ê²°ì •í•©ë‹ˆë‹¤.
    ì´ ì™¸ì—ë„ t-SNE (`TSNE`), LDA (`LinearDiscriminantAnalysis` - ì§€ë„í•™ìŠµ ê¸°ë°˜ ì°¨ì›ì¶•ì†Œ) ë“± ë‹¤ì–‘í•œ ì°¨ì› ì¶•ì†Œ ê¸°ë²•ì´ ìˆìŠµë‹ˆë‹¤.
    """)

else: # df_pca_origê°€ Noneì¼ ê²½ìš° (ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨)
    st.error(f"{chosen_dataset_pca} ë°ì´í„°ì…‹ì„ ë¡œë“œí•  ìˆ˜ ì—†ì–´ PCA ì˜ˆì œë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")